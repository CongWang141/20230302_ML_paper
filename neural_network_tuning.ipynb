{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import Huber\n",
    "import tensorflow_addons as tfa\n",
    "from keras.regularizers import L1L2, L1, L2\n",
    "\n",
    "os.chdir('d:\\\\学习\\\\Paper_under_working\\\\20230101_machine_learning_paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X = pd.read_pickle('data/dataset.pkl')\n",
    "X.set_index('year_month', inplace=True)\n",
    "\n",
    "# define columns variables\n",
    "cols = ['InvestPPEInv', 'ShareIss1Y', 'ShareRepurchase', 'DelCOA', 'dNoa', 'GrLTNOA', 'IntMom', 'LRreversal', 'Mom12m', 'Mom6m', 'MRreversal', 'ResidualMomentum', 'STreversal', 'AM', 'BMdec', 'ChEQ', 'AssetGrowth', 'ChNWC', 'DelEqu', 'NOA', 'Size', 'SP', 'AbnormalAccruals', 'Accruals', 'PctAcc', 'OPLeverage', 'BookLeverage', 'CF', 'cfp', 'DelCOL', 'DelFINL', 'IdioRisk', 'IdioVol3F', 'Leverage', 'Beta', 'BetaFP', 'BidAskSpread', 'DolVol', 'Illiquidity', 'PRC', 'VolMkt', 'VolSD', 'High52', 'MaxRet', 'CashProd', 'GP', 'roaq', 'RoE', 'DelLTI', 'CFNAI', 'P_I', 'EU_H', 'C_H', 'SO_I', 'Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'ab_capm', 'ab_ff3', 'ab_ff5', 'ex_return']\n",
    "\n",
    "# firm feature\n",
    "firm_features = ['InvestPPEInv', 'ShareIss1Y', 'ShareRepurchase', 'DelCOA', 'dNoa', 'GrLTNOA', 'IntMom', 'LRreversal', 'Mom12m', 'Mom6m', 'MRreversal', 'ResidualMomentum', 'STreversal', 'AM', 'BMdec', 'ChEQ', 'AssetGrowth', 'ChNWC', 'DelEqu', 'NOA', 'Size', 'SP', 'AbnormalAccruals', 'Accruals', 'PctAcc', 'OPLeverage', 'BookLeverage', 'CF', 'cfp', 'DelCOL', 'DelFINL', 'IdioRisk', 'IdioVol3F', 'Leverage', 'Beta', 'BetaFP', 'BidAskSpread', 'DolVol', 'Illiquidity', 'PRC', 'VolMkt', 'VolSD', 'High52', 'MaxRet', 'CashProd', 'GP', 'roaq', 'RoE', 'DelLTI']\n",
    "\n",
    "# macro features\n",
    "macro_features = ['CFNAI', 'P_I', 'EU_H', 'C_H', 'SO_I']\n",
    "\n",
    "# fama-french 5 factors\n",
    "ff_5factors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, X_test = train_test_split(X, test_size=1/3, shuffle=True, random_state=100)\n",
    "X_train, X_val = train_test_split(train, test_size=1/2, shuffle=True, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data (standerdized)\n",
    "# fit scaler to train data, and apply it to validation and test data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler()\n",
    "X_train_scaled = scl.fit_transform(X_train[cols])\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled)\n",
    "X_train_scaled.index = X_test.index\n",
    "X_train_scaled.columns = cols\n",
    "\n",
    "X_val_scaled = scl.transform(X_val[cols])\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled)\n",
    "X_val_scaled.index = X_val.index\n",
    "X_val_scaled.columns = cols\n",
    "\n",
    "X_test_scaled = scl.transform(X_test[cols])\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "X_test_scaled.index = X_test.index\n",
    "X_test_scaled.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(X, y, X_val, y_val, penalty, learning_rate, decay_rate, momentum, batch_size):\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=L1(penalty), bias_regularizer=L1(penalty)))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Dense(1, kernel_regularizer=L1(penalty), bias_regularizer=L1(penalty)))\n",
    "\n",
    "# add early stop\n",
    "  earlystop = EarlyStopping(monitor='val_r_square', mode='max', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Compile model\n",
    "\n",
    "  sgd = SGD(learning_rate=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "  model.compile(loss='mse', optimizer=sgd, metrics= [tfa.metrics.RSquare()])\n",
    "  h = model.fit(X, y, epochs=100, batch_size=batch_size, verbose=0, validation_data=(X_val, y_val), callbacks=earlystop)\n",
    "  return h, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(SEED):\n",
    "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  tf.random.set_seed(SEED)\n",
    "  random.seed(SEED)\n",
    "  \n",
    "set_seed(SEED=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 35.\n",
      "Epoch 55: early stopping\n"
     ]
    }
   ],
   "source": [
    "# tunning for predicting abnormal return\n",
    "h, model = model_fit(X=X_train_scaled[firm_features], y=X_train_scaled['ab_ff5'], X_val=X_val_scaled[firm_features], y_val=X_val_scaled['ab_ff5'], penalty=0.001, learning_rate=0.01, decay_rate=0.001, momentum=0.99, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32 nodes:\n",
    "72-57, 67-60, 78-64\n",
    "16 nodes:\n",
    "70-59, 94-70, 75-62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>r_square</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_r_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.004985</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>1.001679</td>\n",
       "      <td>0.006279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.006776</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>1.001698</td>\n",
       "      <td>0.006169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.003591</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>1.000873</td>\n",
       "      <td>0.006105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.001954</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>1.000594</td>\n",
       "      <td>0.005905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.005164</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>1.002993</td>\n",
       "      <td>0.005578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.001963</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>1.000685</td>\n",
       "      <td>0.005526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.008866</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>1.004949</td>\n",
       "      <td>0.005298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.003347</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>1.001612</td>\n",
       "      <td>0.005250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.006992</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>1.003307</td>\n",
       "      <td>0.005118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.015840</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>1.009872</td>\n",
       "      <td>0.004990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.003959</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>1.001880</td>\n",
       "      <td>0.004914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.003352</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>1.002011</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.003756</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>1.002419</td>\n",
       "      <td>0.004702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.003831</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>1.003516</td>\n",
       "      <td>0.004591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.007926</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>1.004466</td>\n",
       "      <td>0.004557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.003457</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>1.002122</td>\n",
       "      <td>0.004526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.008179</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>1.005371</td>\n",
       "      <td>0.004526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.008766</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>1.005427</td>\n",
       "      <td>0.004503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.004907</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>1.002841</td>\n",
       "      <td>0.004488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.030988</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>1.023833</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.014801</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>1.009374</td>\n",
       "      <td>0.004433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.002272</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>1.002174</td>\n",
       "      <td>0.004385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.001282</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>1.001699</td>\n",
       "      <td>0.004369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.008146</td>\n",
       "      <td>0.006058</td>\n",
       "      <td>1.005190</td>\n",
       "      <td>0.004320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.004050</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>1.002284</td>\n",
       "      <td>0.004296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.011242</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>1.008019</td>\n",
       "      <td>0.004121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.003535</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>1.002238</td>\n",
       "      <td>0.003833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.055953</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>1.047503</td>\n",
       "      <td>0.003757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.017765</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>1.013935</td>\n",
       "      <td>0.003621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.002037</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>1.003273</td>\n",
       "      <td>0.003520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.006739</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>1.004671</td>\n",
       "      <td>0.003481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.020191</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>1.015853</td>\n",
       "      <td>0.003374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.067515</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>1.058272</td>\n",
       "      <td>0.003103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.022647</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>1.018222</td>\n",
       "      <td>0.003057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.005074</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>1.005573</td>\n",
       "      <td>0.002960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.082194</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>1.070474</td>\n",
       "      <td>0.002884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.005371</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>1.003865</td>\n",
       "      <td>0.002765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.012383</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>1.009805</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.005562</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>1.004331</td>\n",
       "      <td>0.002678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.016086</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>1.013199</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.009955</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>1.008744</td>\n",
       "      <td>0.002364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.003959</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>1.005306</td>\n",
       "      <td>0.002313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.101124</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>1.087143</td>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.026794</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>1.022223</td>\n",
       "      <td>0.001884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.124844</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>1.107217</td>\n",
       "      <td>0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.007832</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>1.007147</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.037395</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>1.031797</td>\n",
       "      <td>0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.045765</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>1.037530</td>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.052424</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>1.044598</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.154787</td>\n",
       "      <td>-0.001733</td>\n",
       "      <td>1.133526</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.005765</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>1.007770</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.217396</td>\n",
       "      <td>-0.010981</td>\n",
       "      <td>1.196142</td>\n",
       "      <td>-0.003818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.187774</td>\n",
       "      <td>-0.004653</td>\n",
       "      <td>1.169680</td>\n",
       "      <td>-0.006195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.251391</td>\n",
       "      <td>-0.047020</td>\n",
       "      <td>1.252192</td>\n",
       "      <td>-0.045597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.488995</td>\n",
       "      <td>-0.327809</td>\n",
       "      <td>1.500462</td>\n",
       "      <td>-0.316482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  r_square  val_loss  val_r_square\n",
       "34  1.004985  0.007564  1.001679      0.006279\n",
       "38  1.006776  0.005777  1.001698      0.006169\n",
       "42  1.003591  0.007742  1.000873      0.006105\n",
       "45  1.001954  0.009235  1.000594      0.005905\n",
       "30  1.005164  0.008015  1.002993      0.005578\n",
       "49  1.001963  0.008974  1.000685      0.005526\n",
       "24  1.008866  0.006276  1.004949      0.005298\n",
       "44  1.003347  0.008186  1.001612      0.005250\n",
       "32  1.006992  0.006030  1.003307      0.005118\n",
       "19  1.015840  0.003944  1.009872      0.004990\n",
       "47  1.003959  0.007240  1.001880      0.004914\n",
       "40  1.003352  0.008220  1.002011      0.004900\n",
       "43  1.003756  0.007843  1.002419      0.004702\n",
       "33  1.003831  0.008940  1.003516      0.004591\n",
       "28  1.007926  0.005867  1.004466      0.004557\n",
       "48  1.003457  0.007753  1.002122      0.004526\n",
       "25  1.008179  0.006386  1.005371      0.004526\n",
       "26  1.008766  0.005690  1.005427      0.004503\n",
       "39  1.004907  0.007199  1.002841      0.004488\n",
       "13  1.030988  0.004384  1.023833      0.004444\n",
       "20  1.014801  0.003977  1.009374      0.004433\n",
       "46  1.002272  0.008713  1.002174      0.004385\n",
       "50  1.001282  0.009223  1.001699      0.004369\n",
       "27  1.008146  0.006058  1.005190      0.004320\n",
       "53  1.004050  0.007235  1.002284      0.004296\n",
       "22  1.011242  0.005523  1.008019      0.004121\n",
       "54  1.003535  0.007275  1.002238      0.003833\n",
       "9   1.055953  0.004799  1.047503      0.003757\n",
       "17  1.017765  0.005132  1.013935      0.003621\n",
       "41  1.002037  0.009272  1.003273      0.003520\n",
       "37  1.006739  0.005713  1.004671      0.003481\n",
       "16  1.020191  0.004437  1.015853      0.003374\n",
       "8   1.067515  0.004189  1.058272      0.003103\n",
       "15  1.022647  0.004512  1.018222      0.003057\n",
       "31  1.005074  0.007902  1.005573      0.002960\n",
       "7   1.082194  0.003399  1.070474      0.002884\n",
       "51  1.005371  0.005388  1.003865      0.002765\n",
       "21  1.012383  0.005244  1.009805      0.002683\n",
       "52  1.005562  0.005814  1.004331      0.002678\n",
       "18  1.016086  0.005096  1.013199      0.002579\n",
       "23  1.009955  0.006291  1.008744      0.002364\n",
       "35  1.003959  0.008247  1.005306      0.002313\n",
       "6   1.101124  0.002362  1.087143      0.002185\n",
       "14  1.026794  0.003866  1.022223      0.001884\n",
       "5   1.124844  0.000659  1.107217      0.001710\n",
       "29  1.007832  0.005599  1.007147      0.001633\n",
       "12  1.037395  0.003278  1.031797      0.001573\n",
       "11  1.045765  0.000626  1.037530      0.001408\n",
       "10  1.052424  0.000324  1.044598      0.000343\n",
       "4   1.154787 -0.001733  1.133526      0.000123\n",
       "36  1.005765  0.006458  1.007770      0.000039\n",
       "2   1.217396 -0.010981  1.196142     -0.003818\n",
       "3   1.187774 -0.004653  1.169680     -0.006195\n",
       "1   1.251391 -0.047020  1.252192     -0.045597\n",
       "0   1.488995 -0.327809  1.500462     -0.316482"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(h.history).sort_values('val_r_square', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 61.\n",
      "Epoch 81: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>r_square</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_r_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.001434</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>1.006022</td>\n",
       "      <td>0.007030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.011209</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>1.012892</td>\n",
       "      <td>0.006765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.996852</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>1.004718</td>\n",
       "      <td>0.006715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.000407</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>1.005951</td>\n",
       "      <td>0.006712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.999319</td>\n",
       "      <td>0.009898</td>\n",
       "      <td>1.004369</td>\n",
       "      <td>0.006652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.423932</td>\n",
       "      <td>-0.076136</td>\n",
       "      <td>1.486605</td>\n",
       "      <td>-0.146534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.463586</td>\n",
       "      <td>-0.105802</td>\n",
       "      <td>1.538052</td>\n",
       "      <td>-0.180311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.462662</td>\n",
       "      <td>-0.112708</td>\n",
       "      <td>1.590119</td>\n",
       "      <td>-0.230664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.940850</td>\n",
       "      <td>-0.649954</td>\n",
       "      <td>1.636596</td>\n",
       "      <td>-0.327018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.452321</td>\n",
       "      <td>-0.127899</td>\n",
       "      <td>1.687933</td>\n",
       "      <td>-0.344698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  r_square  val_loss  val_r_square\n",
       "60  1.001434  0.009876  1.006022      0.007030\n",
       "42  1.011209  0.006999  1.012892      0.006765\n",
       "73  0.996852  0.012687  1.004718      0.006715\n",
       "62  1.000407  0.010530  1.005951      0.006712\n",
       "80  0.999319  0.009898  1.004369      0.006652\n",
       "..       ...       ...       ...           ...\n",
       "4   1.423932 -0.076136  1.486605     -0.146534\n",
       "3   1.463586 -0.105802  1.538052     -0.180311\n",
       "2   1.462662 -0.112708  1.590119     -0.230664\n",
       "0   1.940850 -0.649954  1.636596     -0.327018\n",
       "1   1.452321 -0.127899  1.687933     -0.344698\n",
       "\n",
       "[81 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuning for predicting excess return \n",
    "h, model = model_fit(X=X_train_scaled[firm_features], y=X_train_scaled['ex_return'], X_val=X_val_scaled[firm_features], y_val=X_val_scaled['ex_return'], penalty=0.001, learning_rate=0.01, decay_rate=0.001, momentum=0.99, batch_size=10000)\n",
    "\n",
    "pd.DataFrame(h.history).sort_values('val_r_square', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>r_square</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_r_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.001434</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>1.006022</td>\n",
       "      <td>0.007030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.011209</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>1.012892</td>\n",
       "      <td>0.006765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.996852</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>1.004718</td>\n",
       "      <td>0.006715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.000407</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>1.005951</td>\n",
       "      <td>0.006712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.999319</td>\n",
       "      <td>0.009898</td>\n",
       "      <td>1.004369</td>\n",
       "      <td>0.006652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.423932</td>\n",
       "      <td>-0.076136</td>\n",
       "      <td>1.486605</td>\n",
       "      <td>-0.146534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.463586</td>\n",
       "      <td>-0.105802</td>\n",
       "      <td>1.538052</td>\n",
       "      <td>-0.180311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.462662</td>\n",
       "      <td>-0.112708</td>\n",
       "      <td>1.590119</td>\n",
       "      <td>-0.230664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.940850</td>\n",
       "      <td>-0.649954</td>\n",
       "      <td>1.636596</td>\n",
       "      <td>-0.327018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.452321</td>\n",
       "      <td>-0.127899</td>\n",
       "      <td>1.687933</td>\n",
       "      <td>-0.344698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  r_square  val_loss  val_r_square\n",
       "60  1.001434  0.009876  1.006022      0.007030\n",
       "42  1.011209  0.006999  1.012892      0.006765\n",
       "73  0.996852  0.012687  1.004718      0.006715\n",
       "62  1.000407  0.010530  1.005951      0.006712\n",
       "80  0.999319  0.009898  1.004369      0.006652\n",
       "..       ...       ...       ...           ...\n",
       "4   1.423932 -0.076136  1.486605     -0.146534\n",
       "3   1.463586 -0.105802  1.538052     -0.180311\n",
       "2   1.462662 -0.112708  1.590119     -0.230664\n",
       "0   1.940850 -0.649954  1.636596     -0.327018\n",
       "1   1.452321 -0.127899  1.687933     -0.344698\n",
       "\n",
       "[81 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(h.history).sort_values('val_r_square', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb7eae22b3a28430044b167b2f91d2eb913632173e49b3dfc217d3fa48268c7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
